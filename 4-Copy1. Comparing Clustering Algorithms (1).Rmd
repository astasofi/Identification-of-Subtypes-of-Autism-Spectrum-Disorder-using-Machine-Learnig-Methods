---
title: "Untitled"
output: html_document
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
source("Functions.R")
```

```{r}
# Load libraries
library(tidyverse)
library(dplyr)
library(clValid)
library(mclust)
library(NbClust)
library(parameters)
library(factoextra)
```

### Load Dataset

```{r}
# Read imputed values file
df <- read.csv("clusters_variables_imputed.csv", row.names = 1)
```

```{r}
# Calculate percentile rank of points values
df <- df %>% mutate(
QD_M = perc.rank(QD_M),
QD_PS = perc.rank(QD_PS),
QD_L = perc.rank(QD_L),
QD_EH = perc.rank(QD_EH),
QD_R = perc.rank(QD_R),
VABS_Com = perc.rank(VABS_Com),
VABS_Aut = perc.rank(VABS_Aut),
VABS_Soc = perc.rank(VABS_Soc),
ADIR_Soc = perc.rank(ADIR_Soc),
ADIR_RRB = perc.rank(ADIR_RRB),
ADIR_AbDev = perc.rank(ADIR_AbDev)
) 
```


### Data preparation
```{r}
dis <- dist(df, method = "euclidean")
```


## Assessing Clustering Tendency

```{r}
#library(clustertend)
# Compute Hopkins statistic for original dataset
# The Hopkins statistic is used to assess the clustering tendency of a data set by measuring the probability that a given data set is generated by a uniform data distribution. In other words, it tests the spatial randomness of the data.

set.seed(123)
res <- get_clust_tendency(df, n = nrow(df)-1)
res$hopkins_stat
```

### Choosing the Best Clustering Algorithms
## Measures for comparing clustering algorithms

```{r}
# Compute clValid
set.seed(123)
clmethods <- c("hierarchical","kmeans","diana","agnes","clara","model","sota")
methods <- c("ward", "single", "complete", "average")
intern <- clValid(df, nClust = 2:6,
                  clMethods = clmethods, validation = c("internal"),
                  method = methods, metric = "euclidean")

# Summary
summary(intern)
```
```{r}
set.seed(123)
stability <- clValid(df, nClust = 2:6,
                  clMethods = c("hierarchical","kmeans", 
                                "diana","agnes","clara","model","sota"),
                  validation = c("stability"),
                  method = methods, metric = "euclidean")
# Summary
summary(stability)
```

```{r}
set.seed(123)
nb <- NbClust(df, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "ward.D2")
nb$Best.nc
```
```{r}
fviz_nbclust(nb)
```

```{r}
set.seed(123)
n_clust <- parameters::n_clusters(df,
                      package = c("easystats", "NbClust", "mclust"),
                      standardize = FALSE)
n_clust
```
```{r}
plot(n_clust)
```




```{r}
for (col in names(df))
{
  print(col)
  dis_mat <- dist(df %>% select(-all_of(col)), method = "euclidean") 
  hc <- hcut(dis_mat, method = "ward.D2") 
  si <- silhouette(cutree(hc, k = 2), dis_mat)
  print(summary(si))
}
```


